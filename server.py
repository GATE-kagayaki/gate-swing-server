import os
import re
import io
import json
import time
import math
import shutil
import tempfile
import traceback
from typing import Any, Dict, Optional, Tuple

import ffmpeg
import numpy as np
import cv2
import mediapipe as mp

from flask import Flask, request, abort, jsonify

from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError, LineBotApiError
from linebot.models import MessageEvent, TextMessage, VideoMessage, TextSendMessage

from google.cloud import tasks_v2
from google.api_core.exceptions import NotFound, PermissionDenied
from google.cloud import firestore as gcfirestore

import firebase_admin
from firebase_admin import credentials, firestore as fbfirestore, initialize_app

from google import genai
from google.genai import errors as genai_errors


# ==================================================
# ENV
# ==================================================
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET", "")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "")
SERVICE_HOST_URL = os.environ.get("SERVICE_HOST_URL", "").rstrip("/")
TASK_SA_EMAIL = os.environ.get("TASK_SA_EMAIL", "")

TASK_QUEUE_LOCATION = os.environ.get("TASK_QUEUE_LOCATION", "asia-northeast2")  # Osaka default
TASK_QUEUE_NAME = os.environ.get("TASK_QUEUE_NAME", "video-analysis-queue")

# Premium behavior
FORCE_PREMIUM = os.environ.get("FORCE_PREMIUM", "true").lower() in ("1", "true", "yes", "on")

# Gemini model preferences (fallback list)
GEMINI_MODEL_ENV = os.environ.get("GEMINI_MODEL", "").strip()

# Analysis tuning
MAX_SECONDS_FOR_ANALYSIS = int(os.environ.get("MAX_SECONDS_FOR_ANALYSIS", "30"))
FRAME_STRIDE = int(os.environ.get("FRAME_STRIDE", "2"))  # analyze every N frames


# ==================================================
# App init
# ==================================================
app = Flask(__name__)
app.config["JSON_AS_ASCII"] = False


# LINE
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN) if LINE_CHANNEL_ACCESS_TOKEN else None
handler = WebhookHandler(LINE_CHANNEL_SECRET) if LINE_CHANNEL_SECRET else None


# Firestore (Firebase Admin recommended on Cloud Run)
db = None
try:
    if not firebase_admin._apps:
        cred = credentials.ApplicationDefault()
        initialize_app(cred, {"projectId": GCP_PROJECT_ID or None})
    db = fbfirestore.client()
except Exception as e:
    print("[Firestore] init failed:", e)
    db = None


# Cloud Tasks
tasks_client = None
queue_path = None
try:
    if GCP_PROJECT_ID:
        tasks_client = tasks_v2.CloudTasksClient()
        queue_path = tasks_client.queue_path(GCP_PROJECT_ID, TASK_QUEUE_LOCATION, TASK_QUEUE_NAME)
except Exception as e:
    print("[CloudTasks] init failed:", e)
    tasks_client = None
    queue_path = None


# ==================================================
# Utilities
# ==================================================
def now_ts() -> float:
    return time.time()


def safe_print_exc(prefix: str = "") -> None:
    print(prefix)
    print(traceback.format_exc())


def firestore_safe_set(report_id: str, data: Dict[str, Any]) -> None:
    if not db:
        return
    try:
        db.collection("reports").document(report_id).set(data, merge=True)
    except Exception:
        safe_print_exc("[Firestore] set failed")


def firestore_safe_update(report_id: str, patch: Dict[str, Any]) -> None:
    if not db:
        return
    try:
        db.collection("reports").document(report_id).update(patch)
    except Exception:
        safe_print_exc("[Firestore] update failed")


def firestore_get(doc_path: Tuple[str, str]) -> Optional[Dict[str, Any]]:
    if not db:
        return None
    try:
        col, doc_id = doc_path
        doc = db.collection(col).document(doc_id).get()
        if doc.exists:
            return doc.to_dict() or {}
        return None
    except Exception:
        safe_print_exc("[Firestore] get failed")
        return None


def safe_line_reply(reply_token: str, text: str) -> None:
    if not line_bot_api:
        return
    try:
        line_bot_api.reply_message(reply_token, TextSendMessage(text=text))
    except LineBotApiError:
        safe_print_exc("[LINE] reply failed")


def safe_line_push(user_id: str, text: str) -> None:
    if not line_bot_api:
        return
    try:
        line_bot_api.push_message(user_id, TextSendMessage(text=text))
    except LineBotApiError:
        safe_print_exc("[LINE] push failed")


def make_initial_reply(report_id: str, plan_label: str) -> str:
    report_url = f"{SERVICE_HOST_URL}/report/{report_id}" if SERVICE_HOST_URL else f"/report/{report_id}"
    return (
        "âœ… å‹•ç”»ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚è§£æã‚’é–‹å§‹ã—ã¾ã™ï¼\n"
        f"ï¼ˆãƒ¢ãƒ¼ãƒ‰ï¼š{plan_label}ï¼‰\n\n"
        "AIã«ã‚ˆã‚‹ã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ã«ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚\n"
        "ã€å‡¦ç†çŠ¶æ³ç¢ºèªURLã€‘\n"
        f"{report_url}\n\n"
        "ã€æ–™é‡‘ãƒ—ãƒ©ãƒ³ã€‘\n"
        "ãƒ»éƒ½åº¦å¥‘ç´„ï¼š500å††ï¼1å›\n"
        "ãƒ»å›æ•°åˆ¸ã€€ï¼š1,980å††ï¼5å›åˆ¸\n"
        "ãƒ»æœˆé¡å¥‘ç´„ï¼š4,980å††ï¼æœˆ"
    )


def make_done_push(report_id: str, is_premium: bool) -> str:
    report_url = f"{SERVICE_HOST_URL}/report/{report_id}" if SERVICE_HOST_URL else f"/report/{report_id}"
    if is_premium:
        return (
            "ğŸ‰ AIã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n\n"
            "ã€è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆURLã€‘\n"
            f"{report_url}\n\n"
            "è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã¯URLã‹ã‚‰ã”ç¢ºèªãã ã•ã„ã€‚æ¬¡ã®ç·´ç¿’ã«ãŠå½¹ç«‹ã¦ãã ã•ã„ï¼"
        )
    return (
        "âœ… ç„¡æ–™ç‰ˆAIã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n\n"
        "ã€ç°¡æ˜“ãƒ¬ãƒãƒ¼ãƒˆURLã€‘\n"
        f"{report_url}\n\n"
        "éª¨æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆ01ï¼‰ã¨ç·åˆè¨ºæ–­ï¼ˆ07ï¼‰ã‚’ã”ç¢ºèªã„ãŸã ã‘ã¾ã™ã€‚"
    )


# ==================================================
# User input capture (optional)
#   Users may send text like:
#     HS:45 ãƒŸã‚¹:ã‚¹ãƒ©ã‚¤ã‚¹ æ€§åˆ¥:ç”· ç•ªæ‰‹:DR
#   Store as "pending_profile" for next video.
# ==================================================
PROFILE_REGEX = re.compile(
    r"""
    (?:
        (?:HS|ãƒ˜ãƒƒãƒ‰ã‚¹ãƒ”ãƒ¼ãƒ‰)\s*[:ï¼š]\s*(?P<hs>\d+(?:\.\d+)?) |
        (?:ãƒŸã‚¹|miss)\s*[:ï¼š]\s*(?P<miss>[^ \n\r\t]+) |
        (?:æ€§åˆ¥|gender)\s*[:ï¼š]\s*(?P<gender>ç”·|å¥³|ç”·æ€§|å¥³æ€§|m|f|M|F) |
        (?:ç•ªæ‰‹|club)\s*[:ï¼š]\s*(?P<club>DR|D|ãƒ‰ãƒ©ã‚¤ãƒãƒ¼|FW|UT|IRON|ã‚¢ã‚¤ã‚¢ãƒ³|WEDGE|ã‚¦ã‚§ãƒƒã‚¸|P|SW|AW)
    )
    """,
    re.IGNORECASE | re.VERBOSE,
)


def parse_profile_text(text: str) -> Dict[str, Any]:
    out: Dict[str, Any] = {}
    for m in PROFILE_REGEX.finditer(text or ""):
        if m.group("hs"):
            try:
                out["head_speed"] = float(m.group("hs"))
            except Exception:
                pass
        if m.group("miss"):
            out["miss_tendency"] = m.group("miss").strip()
        if m.group("gender"):
            g = m.group("gender").strip().lower()
            if g in ("ç”·", "ç”·æ€§", "m"):
                out["gender"] = "male"
            elif g in ("å¥³", "å¥³æ€§", "f"):
                out["gender"] = "female"
        if m.group("club"):
            c = m.group("club").strip().upper()
            if c in ("D", "DR", "ãƒ‰ãƒ©ã‚¤ãƒãƒ¼"):
                out["club"] = "DR"
            elif c in ("FW",):
                out["club"] = "FW"
            elif c in ("UT",):
                out["club"] = "UT"
            elif c in ("IRON", "ã‚¢ã‚¤ã‚¢ãƒ³"):
                out["club"] = "IRON"
            elif c in ("WEDGE", "ã‚¦ã‚§ãƒƒã‚¸", "SW", "AW", "P"):
                out["club"] = "WEDGE"
    return out


def set_pending_profile(user_id: str, profile: Dict[str, Any]) -> None:
    if not db:
        return
    try:
        db.collection("users").document(user_id).set(
            {"pending_profile": profile, "pending_profile_updated_at": fbfirestore.SERVER_TIMESTAMP},
            merge=True,
        )
    except Exception:
        safe_print_exc("[Firestore] set pending_profile failed")


def pop_pending_profile(user_id: str) -> Dict[str, Any]:
    if not db:
        return {}
    try:
        ref = db.collection("users").document(user_id)
        doc = ref.get()
        if not doc.exists:
            return {}
        data = doc.to_dict() or {}
        prof = data.get("pending_profile") or {}
        # clear after use
        ref.set({"pending_profile": fbfirestore.DELETE_FIELD}, merge=True)
        return prof if isinstance(prof, dict) else {}
    except Exception:
        safe_print_exc("[Firestore] pop pending_profile failed")
        return {}


# ==================================================
# Cloud Tasks enqueue with OIDC (required for Cloud Run auth)
# ==================================================
def create_cloud_task(report_id: str, user_id: str, message_id: str) -> str:
    if not tasks_client or not queue_path:
        raise RuntimeError("Cloud Tasks client is not initialized.")
    if not SERVICE_HOST_URL:
        raise RuntimeError("SERVICE_HOST_URL is missing.")
    if not TASK_SA_EMAIL:
        raise RuntimeError("TASK_SA_EMAIL is missing.")

    payload = json.dumps({"report_id": report_id, "user_id": user_id, "message_id": message_id}).encode("utf-8")

    task = {
        "http_request": {
            "http_method": tasks_v2.HttpMethod.POST,
            "url": f"{SERVICE_HOST_URL}/worker/process_video",
            "headers": {"Content-Type": "application/json"},
            "body": payload,
            "oidc_token": {
                "service_account_email": TASK_SA_EMAIL,
                "audience": SERVICE_HOST_URL,
            },
        }
    }
    resp = tasks_client.create_task(parent=queue_path, task=task)
    return resp.name


# ==================================================
# Video handling
# ==================================================
def download_line_video_to_file(message_id: str, dst_path: str) -> None:
    if not line_bot_api:
        raise RuntimeError("LINE bot not initialized.")
    content = line_bot_api.get_message_content(message_id)
    with open(dst_path, "wb") as f:
        for chunk in content.iter_content():
            f.write(chunk)


def transcode_video(input_path: str, output_path: str) -> None:
    """
    Normalize to mp4/h264/aac, resize, limit duration if needed.
    """
    # Use ffmpeg-python
    (
        ffmpeg
        .input(input_path)
        .output(
            output_path,
            vcodec="libx264",
            acodec="aac",
            movflags="+faststart",
            vf="scale='min(720,iw)':-2",
            preset="veryfast",
            crf=28,
            **{"t": MAX_SECONDS_FOR_ANALYSIS},
        )
        .overwrite_output()
        .run(quiet=True)
    )


# ==================================================
# MediaPipe analysis (practical, robust)
#   We compute simple proxy metrics:
#   - frame_count: total frames read
#   - max_head_drift_x: max normalized horizontal drift of nose vs starting
#   - max_knee_sway_x: max normalized horizontal drift of knee midpoint vs starting
#   - max_wrist_cock: angle at lead wrist (shoulder-elbow-wrist) proxy
#   - max_shoulder_rotation: shoulder line angle change (2D) vs address
#   - min_hip_rotation: hip line angle change (2D) vs address
#
# NOTE:
#   This is not "perfect biomechanics", but stable and consistent for service v1.
# ==================================================
def angle_deg(p1, p2, p3) -> float:
    a = np.array([p1[0], p1[1]])
    b = np.array([p2[0], p2[1]])
    c = np.array([p3[0], p3[1]])
    v1 = a - b
    v2 = c - b
    denom = (np.linalg.norm(v1) * np.linalg.norm(v2)) + 1e-9
    cos = float(np.dot(v1, v2) / denom)
    cos = max(-1.0, min(1.0, cos))
    return float(np.degrees(np.arccos(cos)))


def safe_get_landmark_xy(lms, idx: int) -> Optional[Tuple[float, float]]:
    try:
        lm = lms[idx]
        return (float(lm.x), float(lm.y))
    except Exception:
        return None


def line_angle_deg(p_left: Tuple[float, float], p_right: Tuple[float, float]) -> float:
    dx = p_right[0] - p_left[0]
    dy = p_right[1] - p_left[1]
    return float(np.degrees(np.arctan2(dy, dx)))


def analyze_swing(video_path: str) -> Dict[str, Any]:
    if not os.path.exists(video_path):
        return {"error": "video file not found"}

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return {"error": "failed to open video"}

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        enable_segmentation=False,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )

    frame_count = 0
    stride_count = 0

    # Baselines
    start_nose_x = None
    start_knee_mid_x = None
    start_shoulder_angle = None
    start_hip_angle = None

    max_head_drift_x = 0.0
    max_knee_sway_x = 0.0
    max_wrist_cock = 0.0
    max_shoulder_rotation = -999.0
    min_hip_rotation = 999.0

    # mediapipe indices
    NOSE = 0
    L_SHOULDER = 11
    R_SHOULDER = 12
    L_HIP = 23
    R_HIP = 24
    L_ELBOW = 13
    R_ELBOW = 14
    L_WRIST = 15
    R_WRIST = 16
    L_KNEE = 25
    R_KNEE = 26

    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                break
            frame_count += 1
            stride_count += 1
            if stride_count % max(1, FRAME_STRIDE) != 0:
                continue

            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            res = pose.process(rgb)
            if not res.pose_landmarks:
                continue

            lms = res.pose_landmarks.landmark

            nose = safe_get_landmark_xy(lms, NOSE)
            ls = safe_get_landmark_xy(lms, L_SHOULDER)
            rs = safe_get_landmark_xy(lms, R_SHOULDER)
            lh = safe_get_landmark_xy(lms, L_HIP)
            rh = safe_get_landmark_xy(lms, R_HIP)
            lk = safe_get_landmark_xy(lms, L_KNEE)
            rk = safe_get_landmark_xy(lms, R_KNEE)

            le = safe_get_landmark_xy(lms, L_ELBOW)
            lw = safe_get_landmark_xy(lms, L_WRIST)
            re_ = safe_get_landmark_xy(lms, R_ELBOW)
            rw = safe_get_landmark_xy(lms, R_WRIST)

            if nose and start_nose_x is None:
                start_nose_x = nose[0]
            if lk and rk and start_knee_mid_x is None:
                start_knee_mid_x = (lk[0] + rk[0]) / 2.0

            # drift
            if nose and start_nose_x is not None:
                max_head_drift_x = max(max_head_drift_x, abs(nose[0] - start_nose_x))
            if lk and rk and start_knee_mid_x is not None:
                knee_mid_x = (lk[0] + rk[0]) / 2.0
                max_knee_sway_x = max(max_knee_sway_x, abs(knee_mid_x - start_knee_mid_x))

            # shoulder / hip angles
            if ls and rs:
                ang = line_angle_deg(ls, rs)
                if start_shoulder_angle is None:
                    start_shoulder_angle = ang
                rot = ang - start_shoulder_angle
                max_shoulder_rotation = max(max_shoulder_rotation, rot)
            if lh and rh:
                ang = line_angle_deg(lh, rh)
                if start_hip_angle is None:
                    start_hip_angle = ang
                rot = ang - start_hip_angle
                min_hip_rotation = min(min_hip_rotation, rot)

            # wrist cock proxy (use lead arm: left for right-handed majority; still works as proxy)
            if ls and le and lw:
                wc = angle_deg(ls, le, lw)  # shoulder-elbow-wrist
                max_wrist_cock = max(max_wrist_cock, wc)

        # sanity defaults
        if max_shoulder_rotation == -999.0:
            max_shoulder_rotation = 0.0
        if min_hip_rotation == 999.0:
            min_hip_rotation = 0.0

        return {
            "frame_count": int(frame_count),
            "max_shoulder_rotation": float(round(max_shoulder_rotation, 1)),
            "min_hip_rotation": float(round(min_hip_rotation, 1)),
            "max_wrist_cock": float(round(max_wrist_cock, 1)),
            "max_head_drift_x": float(round(max_head_drift_x, 4)),
            "max_knee_sway_x": float(round(max_knee_sway_x, 4)),
        }

    except Exception:
        safe_print_exc("[MediaPipe] analysis failed")
        return {"error": "mediapipe analysis failed"}

    finally:
        cap.release()
        try:
            pose.close()
        except Exception:
            pass


# ==================================================
# Gemini helpers: structured JSON output
#   AI writes only the content parts, we keep layout fixed.
# ==================================================
def choose_gemini_models() -> Tuple[str, ...]:
    if GEMINI_MODEL_ENV:
        return (GEMINI_MODEL_ENV,)
    return (
        "gemini-1.5-pro",
        "gemini-1.5-flash",
        "gemini-2.0-flash",
        "models/gemini-1.5-pro",
        "models/gemini-1.5-flash",
        "models/gemini-2.0-flash",
    )


def extract_json_object(text: str) -> Optional[Dict[str, Any]]:
    """
    Gemini may wrap in ```json. Extract first {...} block safely.
    """
    if not text:
        return None
    t = text.strip()
    # remove fences
    t = re.sub(r"```(?:json)?", "", t, flags=re.IGNORECASE).replace("```", "")
    # find first JSON object
    m = re.search(r"\{[\s\S]*\}", t)
    if not m:
        return None
    candidate = m.group(0)
    try:
        return json.loads(candidate)
    except Exception:
        return None


def run_gemini_sections(raw_data: Dict[str, Any], is_premium: bool) -> Dict[str, Any]:
    """
    Returns dict with:
      sec02_bullets, sec02_pro,
      sec03_bullets, sec03_pro,
      sec04_bullets, sec04_pro,
      sec05_bullets, sec05_pro,
      sec06_bullets, sec06_pro,
      sec07_good, sec07_improve,
      sec10_text
    """
    # fallback templates in case Gemini fails
    fallback = {
        "sec02_bullets": [
            "é ­ã®å·¦å³ç§»å‹•ãŒå°ã•ãã€ã‚¹ã‚¤ãƒ³ã‚°ä¸­ã®è»¸ãŒæ¯”è¼ƒçš„ä¿ãŸã‚Œã¦ã„ã‚‹ã¨è©•ä¾¡ã§ãã¾ã™ã€‚",
            "ä¸Šä½“ãŒçªã£è¾¼ã¿ã«ããã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®å†ç¾æ€§ã‚’ä½œã‚Šã‚„ã™ã„åœŸå°ãŒã‚ã‚Šã¾ã™ã€‚",
            "ã“ã®å®‰å®šæ€§ã‚’æ´»ã‹ã™ã“ã¨ã§ã€å›è»¢é‡ã®æ”¹å–„ãŒãã®ã¾ã¾æˆæœã«ã¤ãªãŒã‚Šã‚„ã™ã„çŠ¶æ…‹ã§ã™ã€‚",
        ],
        "sec02_pro": "ãƒ—ãƒ­ç›®ç·šã§ã¯ã€Œã¾ãšç›´ã™ç‚¹ã€ã§ã¯ãªãã€Œæ´»ã‹ã™åœŸå°ã€ã¨åˆ¤æ–­ã—ã¾ã™ã€‚ã“ã“ãŒå®‰å®šã—ã¦ã„ã‚‹ã¨ã€ä»–ã®æ”¹å–„ãŒé€Ÿãå½¢ã«ãªã‚Šã¾ã™ã€‚",
        "sec03_bullets": [
            "ä¸ŠåŠèº«ã®æ»è»¢é‡ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ãƒãƒƒã‚¯ã‚¹ã‚¤ãƒ³ã‚°ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æºœã‚ãã‚Œã¦ã„ãªã„ã¨è©•ä¾¡ã§ãã¾ã™ã€‚",
            "ä½“å¹¹ã‚ˆã‚Šè…•ä¸»å°ã«ãªã‚Šã‚„ã™ãã€é£›è·é›¢ã¨å†ç¾æ€§ã®ä¸¡é¢ã§ãƒ­ã‚¹ãŒå‡ºã‚„ã™ã„çŠ¶æ…‹ã§ã™ã€‚",
            "åˆ‡ã‚Šè¿”ã—ä»¥é™ã§æ‰‹å…ˆã®è£œæ­£ãŒå¢—ãˆã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒæ—¥ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚",
        ],
        "sec03_pro": "è‚©å›æ—‹ãŒå¢—ãˆã‚‹ã ã‘ã§ã‚¹ã‚¤ãƒ³ã‚°åŠ¹ç‡ãŒä¸€æ®µä¸ŠãŒã‚‹ã‚¿ã‚¤ãƒ—ã§ã™ã€‚å®‰å®šæ€§ãŒã‚ã‚‹ã®ã§ã€å›ã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ä¼¸ã³æ–¹ãŒå¤§ãã„ã¨è¦‹ã¾ã™ã€‚",
        "sec04_bullets": [
            "ä¸‹åŠèº«ã®å›æ—‹ãŒä¸ŠåŠèº«ã¨å™›ã¿åˆã„ã«ããã€æ»è»¢å·®ãŒä½œã‚Šã«ãã„çŠ¶æ…‹ã¨è©•ä¾¡ã§ãã¾ã™ã€‚",
            "è…°ãŒå…ˆã«å‹•ãã‚„ã™ã„ã¨ã€ã‚¯ãƒ©ãƒ–ã®ä¸‹ã‚Šã‚‹ä½ç½®ãŒä¸å®‰å®šã«ãªã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚",
            "ä¸ŠåŠèº«ã®å›è»¢ãŒæ”¹å–„ã™ã‚‹ã¨ã€è…°ã®å‹•ãã‚‚æ•´ç†ã•ã‚Œã‚„ã™ã„å‚¾å‘ã§ã™ã€‚",
        ],
        "sec04_pro": "è…°å˜ä½“ã‚’ç›´ã™ã‚ˆã‚Šã€è‚©å›æ—‹ã¨é€£å‹•ã®ä½œã‚Šç›´ã—ãŒå„ªå…ˆã§ã™ã€‚é †ç•ªã‚’é–“é•ãˆãªã„ã“ã¨ãŒé‡è¦ã§ã™ã€‚",
        "sec05_bullets": [
            "æ‰‹é¦–ã®å‹•ããŒå¤§ãããªã‚Šã‚„ã™ãã€ãƒªãƒªãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒã¶ã‚Œã‚„ã™ã„çŠ¶æ…‹ã¨è©•ä¾¡ã§ãã¾ã™ã€‚",
            "ä½“å¹¹ã®å›è»¢ä¸è¶³ã‚’æ‰‹é¦–ã§è£œã†ã¨ã€ãƒŸã‚¹ã®å†ç¾æ€§ãŒä¸ŠãŒã‚Šã«ãããªã‚Šã¾ã™ã€‚",
            "å›è»¢é‡ãŒæ•´ã†ã»ã©ã€æ‰‹é¦–ã®å‹•ãã¯è‡ªç„¶ã«é©æ­£åŒ–ã—ã‚„ã™ã„ã‚¿ã‚¤ãƒ—ã§ã™ã€‚",
        ],
        "sec05_pro": "æ‰‹é¦–ã‚’æŠ‘ãˆè¾¼ã‚€ã‚ˆã‚Šã€Œä½“ã§æŒ¯ã‚Œã‚‹æ¡ä»¶ã€ã‚’ä½œã‚‹æ–¹ãŒæ”¹å–„ãŒé€Ÿã„ã¨åˆ¤æ–­ã—ã¾ã™ã€‚",
        "sec06_bullets": [
            "ä¸‹åŠèº«ã®å·¦å³ãƒ–ãƒ¬ãŒå°ã•ãã€åœŸå°ãŒå®‰å®šã—ã¦ã„ã‚‹ã¨è©•ä¾¡ã§ãã¾ã™ã€‚",
            "åˆ‡ã‚Šè¿”ã—ã§ãƒãƒ©ãƒ³ã‚¹ã‚’å´©ã—ã«ããã€å†ç¾æ€§ã‚’ç©ã¿ä¸Šã’ã‚„ã™ã„çŠ¶æ…‹ã§ã™ã€‚",
            "ä¸ŠåŠèº«ã®æ”¹å–„ãŒé€²ã‚€ã¨ã€å®‰å®šæ€§ãŒãã®ã¾ã¾ã‚·ãƒ§ãƒƒãƒˆã®å®‰å®šã«ã¤ãªãŒã‚Šã‚„ã™ã„ã§ã™ã€‚",
        ],
        "sec06_pro": "ä¸‹åŠèº«ãŒå®‰å®šã—ã¦ã„ã‚‹äººã¯ã€ä¸ŠåŠèº«ã®å›è»¢æ”¹å–„ã®æˆæœãŒå‡ºã‚„ã™ã„ã§ã™ã€‚ä¼¸ã³ä»£ãŒå¤§ãã„éƒ¨é¡ã§ã™ã€‚",
        "sec07_good": [
            "é ­ã¨ä¸‹åŠèº«ã®ãƒ–ãƒ¬ãŒå°‘ãªãã€ã‚¹ã‚¤ãƒ³ã‚°ã®åœŸå°ãŒå®‰å®šã—ã¦ã„ã¾ã™ã€‚",
            "å®‰å®šæ€§ãŒã‚ã‚‹ãŸã‚ã€æ”¹å–„ã‚’å…¥ã‚ŒãŸã¨ãã«çµæœã¸åæ˜ ã•ã‚Œã‚„ã™ã„çŠ¶æ…‹ã§ã™ã€‚",
        ],
        "sec07_improve": [
            "ä¸ŠåŠèº«ã®æ»è»¢é‡ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ä½“å¹¹ã®ãƒ‘ãƒ¯ãƒ¼ä¼é”ãŒå¼±ããªã£ã¦ã„ã¾ã™ã€‚",
            "ãã®å½±éŸ¿ã§æ‰‹é¦–ã®å‹•ããŒå¤§ãããªã‚Šã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã‚ºãƒ¬ãŒç”Ÿã˜ã‚„ã™ã„çŠ¶æ…‹ã§ã™ã€‚",
        ],
        "sec10_text": (
            "ä»Šå›ã®ã‚¹ã‚¤ãƒ³ã‚°ã¯ã€é ­ã¨ä¸‹åŠèº«ã®å®‰å®šæ€§ã¨ã„ã†å¼·ã„åœŸå°ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ã†ãˆã§å¤§ããªæ­¦å™¨ã§ã™ã€‚\n\n"
            "ä¸€æ–¹ã§ã€è‚©ã®å›æ—‹é‡ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨ã§ã€ä½“å¹¹ã‚’ä½¿ã£ãŸãƒ‘ãƒ¯ãƒ¼ç”ŸæˆãŒååˆ†ã«è¡Œã‚ã‚Œã¦ãŠã‚‰ãšã€é£›è·é›¢ã¨å®‰å®šæ€§ã®ä¸¡é¢ã§ãƒ­ã‚¹ãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚"
            "ãã®ä¸è¶³åˆ†ã‚’æ‰‹é¦–ã®å‹•ãã§è£œã†å½¢ã«ãªã‚Šã‚„ã™ãã€æ—¥ã«ã‚ˆã£ã¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒå¤‰ã‚ã‚Šã‚„ã™ã„å‚¾å‘ã‚‚è¦‹ã‚‰ã‚Œã¾ã™ã€‚\n\n"
            "ã¾ãšã¯ä¸ŠåŠèº«ã®å›è»¢é‡ã‚’å¢—ã‚„ã—ã€å›è»¢ä¸»å°ã§ã‚¯ãƒ©ãƒ–ãŒå‹•ãæ¡ä»¶ã‚’ä½œã‚‹ã“ã¨ãŒæœ€å„ªå…ˆã§ã™ã€‚"
            "åœŸå°ãŒå®‰å®šã—ã¦ã„ã‚‹ãŸã‚ã€æ”¹å–„ãŒé€²ã‚€ã»ã©æˆæœãŒå‡ºã‚„ã™ã„ã‚¿ã‚¤ãƒ—ã§ã™ã€‚"
            "å®šæœŸçš„ã«è¨ˆæ¸¬ã—ã€æ•°å€¤ã®å¤‰åŒ–ã¨æ„Ÿè¦šã‚’ã‚»ãƒƒãƒˆã§ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚\n\n"
            "ãŠå®¢æ§˜ã®ã‚´ãƒ«ãƒ•ãƒ©ã‚¤ãƒ•ãŒå……å®Ÿã—ãŸã‚‚ã®ã«ãªã‚‹ã“ã¨ã‚’åˆ‡ã«é¡˜ã£ã¦ã„ã¾ã™ã€‚"
        ),
    }

    if not GEMINI_API_KEY:
        return fallback

    client = genai.Client(api_key=GEMINI_API_KEY)

    # Ask for strict JSON
    prompt = (
        "ã‚ãªãŸã¯ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ã‚´ãƒ«ãƒ•ã‚¹ã‚¤ãƒ³ã‚°ã‚³ãƒ¼ãƒã§ã™ã€‚"
        "ä»¥ä¸‹ã®éª¨æ ¼è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã€è©•ä¾¡æ–‡ã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "é‡è¦: ä¸€èˆ¬è«–ã§ã¯ãªãã€ä»Šå›ã®æ•°å€¤ã‹ã‚‰ã“ã®ã‚¹ã‚¤ãƒ³ã‚°ã‚’ã©ã†è©•ä¾¡ã™ã‚‹ã‹ã€ã ã‘ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
        "å‡ºåŠ›ã¯å¿…ãš JSON ã®ã¿ã€‚æ—¥æœ¬èªã€‚ãƒˆãƒ¼ãƒ³ã¯æ™®é€šã€‚ç®‡æ¡æ›¸ãã¯çŸ­æ–‡ã€‚\n\n"
        "ã€å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒã€‘\n"
        "{\n"
        '  "sec02_bullets": ["...","...","..."],\n'
        '  "sec02_pro": "...",\n'
        '  "sec03_bullets": ["...","...","..."],\n'
        '  "sec03_pro": "...",\n'
        '  "sec04_bullets": ["...","...","..."],\n'
        '  "sec04_pro": "...",\n'
        '  "sec05_bullets": ["...","...","..."],\n'
        '  "sec05_pro": "...",\n'
        '  "sec06_bullets": ["...","...","..."],\n'
        '  "sec06_pro": "...",\n'
        '  "sec07_good": ["...","..."],\n'
        '  "sec07_improve": ["...","..."],\n'
        '  "sec10_text": "...."\n'
        "}\n\n"
        "ã€åˆ¶ç´„ã€‘\n"
        "- sec02ã€œ06: bulletsã¯å„3å€‹ã€‚proã¯2ã€œ3æ–‡ã€‚\n"
        "- sec07_good / sec07_improve ã¯å„2å€‹ã€‚\n"
        "- sec10_text ã¯4ã€œ8æ®µè½ç›¸å½“ã§ã€æœ€å¾Œã¯ã€ãŠå®¢æ§˜ã®ã‚´ãƒ«ãƒ•ãƒ©ã‚¤ãƒ•ãŒå……å®Ÿã—ãŸã‚‚ã®ã«ãªã‚‹ã“ã¨ã‚’åˆ‡ã«é¡˜ã£ã¦ã„ã¾ã™ã€‚ã€ã§ç· ã‚ã‚‹ã€‚\n\n"
        f"ã€éª¨æ ¼è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã€‘\n{json.dumps(raw_data, ensure_ascii=False, indent=2)}\n"
    )

    last_err = None
    for model in choose_gemini_models():
        try:
            resp = client.models.generate_content(model=model, contents=prompt)
            text = getattr(resp, "text", "") or ""
            data = extract_json_object(text)
            if not isinstance(data, dict):
                raise RuntimeError("Gemini output is not JSON")
            # minimal validation / fill missing with fallback
            for k, v in fallback.items():
                if k not in data or not data[k]:
                    data[k] = v
            return data
        except (genai_errors.ClientError, genai_errors.ServerError) as e:
            last_err = e
            print("[Gemini] model failed:", model, str(e))
            continue
        except Exception as e:
            last_err = e
            print("[Gemini] unexpected:", model, str(e))
            continue

    print("[Gemini] fallback due to error:", last_err)
    return fallback


# ==================================================
# 09 fitting rules (driver only, premium only)
#   Based on:
#     - head_speed (optional)
#     - raw_data tendencies
# ==================================================
def fit_weight(head_speed: Optional[float]) -> str:
    if head_speed is None:
        return "50gå°ï¼ˆç›®å®‰ï¼‰"
    hs = head_speed
    if hs < 32:
        return "40gå°ã€œ50gå°å‰åŠ"
    if hs < 38:
        return "50gå°å‰åŠã€œä¸­ç›¤"
    if hs < 45:
        return "50gå°å¾ŒåŠã€œ60gå°"
    return "60gå°ã€œ70gå°"


def fit_flex(head_speed: Optional[float]) -> str:
    if head_speed is None:
        return "Rã€œSRï¼ˆç›®å®‰ï¼‰"
    hs = head_speed
    if hs < 32:
        return "L / A"
    if hs < 38:
        return "R"
    if hs < 45:
        return "SR"
    return "Sã€œX"


def fit_torque(head_speed: Optional[float]) -> str:
    if head_speed is None:
        return "3.8ã€œ4.8ï¼ˆç›®å®‰ï¼‰"
    hs = head_speed
    if hs < 32:
        return "5.0ã€œ6.5"
    if hs < 38:
        return "4.5ã€œ5.5"
    if hs < 45:
        return "3.8ã€œ4.8"
    return "3.0ã€œ4.2"


def fit_kick(raw_data: Dict[str, Any]) -> str:
    # simple tendency-based choice:
    shoulder = float(raw_data.get("max_shoulder_rotation", 0.0) or 0.0)
    wrist = float(raw_data.get("max_wrist_cock", 0.0) or 0.0)
    # If shoulder turn low, help launch/feel head: mid or mid-high
    if shoulder < 20:
        return "ä¸­èª¿å­"
    # If wrist motion huge (tendency to timing issue), stabilize: middle or butt
    if wrist > 140:
        return "å…ƒèª¿å­"
    return "ä¸­èª¿å­"


def fitting_table(raw_data: Dict[str, Any], profile: Dict[str, Any]) -> Dict[str, str]:
    hs = profile.get("head_speed")
    try:
        hs = float(hs) if hs is not None else None
    except Exception:
        hs = None

    return {
        "ã‚·ãƒ£ãƒ•ãƒˆé‡é‡": fit_weight(hs),
        "ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹": fit_flex(hs),
        "ã‚­ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ": fit_kick(raw_data),
        "ãƒˆãƒ«ã‚¯": fit_torque(hs),
    }


# ==================================================
# Report assembly (STRUCTURE FIXED)
#   Free: 01 + 07 only
#   Premium: 01-10 full (02-06 bullets + pro, 08/09 tables)
# ==================================================
IDEALS = {
    "frame_count": "60ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Š",
    "max_shoulder_rotation": "ç´„80Â°ã€œ100Â°",
    "min_hip_rotation": "ç´„35Â°ã€œ45Â°",
    "max_wrist_cock": "ç´„90Â°ã€œ120Â°",
    "max_head_drift_x": "0.05ä»¥ä¸‹ï¼ˆå°ã•ã„ã»ã©å®‰å®šï¼‰",
    "max_knee_sway_x": "0.05ä»¥ä¸‹ï¼ˆå°ã•ã„ã»ã©å®‰å®šï¼‰",
}

MEANINGS = {
    "frame_count": "ã‚¹ã‚¤ãƒ³ã‚°å…¨ä½“ã‚’é€šã—ãŸåˆ†æã®ç²’åº¦ã§ã™ã€‚ååˆ†ãªãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒã‚ã‚‹ã»ã©å‚¾å‘ãŒå®‰å®šã—ã¦è¦‹ãˆã¾ã™ã€‚",
    "max_shoulder_rotation": "ä¸ŠåŠèº«ã®æ»è»¢é‡ã®ç›®å®‰ã§ã™ã€‚ã“ã®æ•°å€¤ãŒå¤§ãã„ã»ã©ä½“å¹¹ã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªã‚¹ã‚¤ãƒ³ã‚°ã«ãªã‚Šã‚„ã™ã„ã¨ã•ã‚Œã¾ã™ã€‚",
    "min_hip_rotation": "è…°ã®å›æ—‹é‡ã®ç›®å®‰ã§ã™ã€‚ä¸ŠåŠèº«ã¨ã®æ»è»¢å·®ï¼ˆXãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼‰ã‚’ä½œã‚‹é‡è¦è¦ç´ ã§ã™ã€‚",
    "max_wrist_cock": "æ‰‹é¦–ã®ã‚³ãƒƒã‚¯é‡ã®ç›®å®‰ã§ã™ã€‚é©æ­£ç¯„å›²ã§ä¿ã¦ã‚‹ã¨ãƒ˜ãƒƒãƒ‰ã‚¹ãƒ”ãƒ¼ãƒ‰å‘ä¸Šã«ç¹‹ãŒã‚Šã‚„ã™ã„ã§ã™ã€‚",
    "max_head_drift_x": "é ­ã®å·¦å³ãƒ–ãƒ¬ã®ç›®å®‰ã§ã™ã€‚å°ã•ã„ã»ã©è»¸ãŒå®‰å®šã—ã€å†ç¾æ€§ã®é«˜ã„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã«ç¹‹ãŒã‚Šã‚„ã™ã„ã§ã™ã€‚",
    "max_knee_sway_x": "è†ï¼ˆä¸‹åŠèº«ï¼‰ã®å·¦å³ãƒ–ãƒ¬ã®ç›®å®‰ã§ã™ã€‚å°ã•ã„ã»ã©åœŸå°ãŒå®‰å®šã—ã€ã‚·ãƒ§ãƒƒãƒˆãŒå®‰å®šã—ã‚„ã™ã„ã§ã™ã€‚",
}


def fmt(v: Any) -> str:
    if v is None:
        return "N/A"
    if isinstance(v, (int, float)):
        # keep as-is; caller may append unit
        return str(v)
    return str(v)


def build_markdown_report(
    raw: Dict[str, Any],
    sections: Dict[str, Any],
    is_premium: bool,
    profile: Dict[str, Any],
) -> str:
    # 01 table (always)
    lines = []
    lines.append("## 01. éª¨æ ¼è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ï¼ˆAIãŒæ¸¬ã£ãŸæ•°å€¤ï¼‰\n")

    # Table + short explanation under each (as requested)
    lines.append("| è¨ˆæ¸¬é …ç›® | æ¸¬å®šå€¤ | ç†æƒ³ã®ç›®å®‰ |")
    lines.append("|---|---:|---|")

    lines.append(f"| è§£æãƒ•ãƒ¬ãƒ¼ãƒ æ•° | {fmt(raw.get('frame_count'))} | {IDEALS['frame_count']} |")
    lines.append(f"| æœ€å¤§è‚©å›è»¢ | {fmt(raw.get('max_shoulder_rotation'))}Â° | {IDEALS['max_shoulder_rotation']} |")
    lines.append(f"| æœ€å°è…°å›è»¢ | {fmt(raw.get('min_hip_rotation'))}Â° | {IDEALS['min_hip_rotation']} |")
    lines.append(f"| æœ€å¤§ã‚³ãƒƒã‚¯è§’ | {fmt(raw.get('max_wrist_cock'))}Â° | {IDEALS['max_wrist_cock']} |")
    lines.append(f"| æœ€å¤§é ­ãƒ–ãƒ¬ï¼ˆSwayï¼‰ | {fmt(raw.get('max_head_drift_x'))} | {IDEALS['max_head_drift_x']} |")
    lines.append(f"| æœ€å¤§è†ãƒ–ãƒ¬ï¼ˆSwayï¼‰ | {fmt(raw.get('max_knee_sway_x'))} | {IDEALS['max_knee_sway_x']} |")

    lines.append("\n### å„æ•°å€¤ã®è¦‹æ–¹ï¼ˆç°¡å˜ãªèª¬æ˜ï¼‰\n")
    lines.append(f"**è§£æãƒ•ãƒ¬ãƒ¼ãƒ æ•°**ï¼š{MEANINGS['frame_count']}")
    lines.append(f"\n**æœ€å¤§è‚©å›è»¢**ï¼š{MEANINGS['max_shoulder_rotation']}")
    lines.append(f"\n**æœ€å°è…°å›è»¢**ï¼š{MEANINGS['min_hip_rotation']}")
    lines.append(f"\n**æœ€å¤§ã‚³ãƒƒã‚¯è§’**ï¼š{MEANINGS['max_wrist_cock']}")
    lines.append(f"\n**æœ€å¤§é ­ãƒ–ãƒ¬ï¼ˆSwayï¼‰**ï¼š{MEANINGS['max_head_drift_x']}")
    lines.append(f"\n**æœ€å¤§è†ãƒ–ãƒ¬ï¼ˆSwayï¼‰**ï¼š{MEANINGS['max_knee_sway_x']}\n")

    # 02-06 (premium only)
    if is_premium:
        def sec(title: str, measure_label: str, measure_value: str, bullets_key: str, pro_key: str):
            lines.append(f"\n## {title}\n")
            lines.append(f"**æ¸¬å®šå€¤ï¼š{measure_label} {measure_value}**\n")
            for b in sections.get(bullets_key, []):
                lines.append(f"- {b}")
            lines.append("\n**ãƒ—ãƒ­è©•ä¾¡**")
            lines.append(f"{sections.get(pro_key, '')}\n")

        sec("02. é ­ã®å®‰å®šæ€§ï¼ˆè»¸ã®ãƒ–ãƒ¬ï¼‰", "æœ€å¤§é ­ãƒ–ãƒ¬ï¼ˆSwayï¼‰", fmt(raw.get("max_head_drift_x")), "sec02_bullets", "sec02_pro")
        sec("03. è‚©ã®å›æ—‹ï¼ˆä¸ŠåŠèº«ã®ã­ã˜ã‚Šï¼‰", "æœ€å¤§è‚©å›è»¢", f"{fmt(raw.get('max_shoulder_rotation'))}Â°", "sec03_bullets", "sec03_pro")
        sec("04. è…°ã®å›æ—‹ï¼ˆä¸‹åŠèº«ã®å‹•ãï¼‰", "æœ€å°è…°å›è»¢", f"{fmt(raw.get('min_hip_rotation'))}Â°", "sec04_bullets", "sec04_pro")
        sec("05. æ‰‹é¦–ã®ãƒ¡ã‚«ãƒ‹ã‚¯ã‚¹ï¼ˆã‚³ãƒƒã‚¯è§’ï¼‰", "æœ€å¤§ã‚³ãƒƒã‚¯è§’", f"{fmt(raw.get('max_wrist_cock'))}Â°", "sec05_bullets", "sec05_pro")
        sec("06. ä¸‹åŠèº«ã®å®‰å®šæ€§ï¼ˆè†ã®ãƒ–ãƒ¬ï¼‰", "æœ€å¤§è†ãƒ–ãƒ¬ï¼ˆSwayï¼‰", fmt(raw.get("max_knee_sway_x")), "sec06_bullets", "sec06_pro")

    # 07 (always; requested: two items; bullets)
    lines.append("\n## 07. ç·åˆè¨ºæ–­\n")
    lines.append("### å®‰å®šã—ã¦ã„ã‚‹ç‚¹")
    for b in sections.get("sec07_good", []):
        lines.append(f"- {b}")
    lines.append("\n### æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹ç‚¹")
    for b in sections.get("sec07_improve", []):
        lines.append(f"- {b}")

    # 08 (premium only) - table with richer steps
    if is_premium:
        lines.append("\n## 08. æ”¹å–„æˆ¦ç•¥ã¨ãƒ‰ãƒªãƒ«\n")
        lines.append("| ãƒ‰ãƒªãƒ«å | ç›®çš„ | ã‚„ã‚Šæ–¹ |")
        lines.append("|---|---|---|")
        lines.append("| ã‚¯ãƒ­ã‚¹ã‚¢ãƒ¼ãƒ ã‚¿ãƒ¼ãƒ³ | è‚©å›æ—‹é‡ã®å‘ä¸Š | â‘  ä¸¡è…•ã‚’èƒ¸ã®å‰ã§è»½ãã‚¯ãƒ­ã‚¹ã™ã‚‹<br>â‘¡ ä¸‹åŠèº«ã‚’å›ºå®šã—ãŸã¾ã¾ã€èƒ¸ã‚’ãƒãƒƒã‚¯ã‚¹ã‚¤ãƒ³ã‚°æ–¹å‘ã¸å›ã™<br>â‘¢ è‚©ã§ã¯ãªãã€Œèƒ¸ãŒå›ã‚‹æ„Ÿè¦šã€ã‚’æ„è­˜ã—ã¦å·¦å³äº¤äº’ã«è¡Œã† |")
        lines.append("| ã‚¦ã‚©ãƒ¼ãƒ«ã‚¿ãƒ¼ãƒ³ | è»¸ã‚’ä¿ã£ãŸå›è»¢ç¿’å¾— | â‘  ãŠå°»ã‚’å£ã«è»½ãè§¦ã‚Œã•ã›ã¦ã‚¢ãƒ‰ãƒ¬ã‚¹å§¿å‹¢ã‚’ä½œã‚‹<br>â‘¡ ãŠå°»ã®ä½ç½®ã‚’ä¿ã£ãŸã¾ã¾ä¸ŠåŠèº«ã‚’å›ã™<br>â‘¢ å£ã‹ã‚‰é›¢ã‚Œãšã«å›ã‚Œã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ |")
        lines.append("| L to L ã‚¹ã‚¤ãƒ³ã‚° | æ‰‹é¦–ä¾å­˜ã®è»½æ¸› | â‘  ã‚¯ãƒ©ãƒ–ã‚’è…°ã‹ã‚‰è…°ã¾ã§ã®æŒ¯ã‚Šå¹…ã§æ§‹ãˆã‚‹<br>â‘¡ ä½“ã®å›è»¢ã§ã‚¯ãƒ©ãƒ–ã‚’å‹•ã‹ã™æ„è­˜ã§æŒ¯ã‚‹<br>â‘¢ æ‰‹é¦–ã§æ“ä½œã›ãšã€æŒ¯ã‚Šå¹…ã¨ãƒªã‚ºãƒ ã‚’ä¸€å®šã«ä¿ã¤ |")

    # 09 (premium only) - driver only + notice line
    if is_premium:
        lines.append("\n## 09. ã‚¹ã‚¤ãƒ³ã‚°å‚¾å‘è£œæ­£å‹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®ã¿ï¼‰\n")
        if (profile.get("club") and str(profile.get("club")).upper() != "DR"):
            lines.append("â€»æœ¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ãƒ‰ãƒ©ã‚¤ãƒãƒ¼å°‚ç”¨ã®ãŸã‚ã€ç•ªæ‰‹ãŒãƒ‰ãƒ©ã‚¤ãƒãƒ¼ä»¥å¤–ã®å ´åˆã¯å‚è€ƒæƒ…å ±ã¨ã—ã¦ã”ç¢ºèªãã ã•ã„ã€‚\n")

        ft = fitting_table(raw, profile)
        lines.append("| é …ç›® | æ¨å¥¨ | ç†ç”± |")
        lines.append("|---|---|---|")
        lines.append(f"| ã‚·ãƒ£ãƒ•ãƒˆé‡é‡ | {ft['ã‚·ãƒ£ãƒ•ãƒˆé‡é‡']} | ã‚¹ã‚¤ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’æãªã‚ãšã€æŒ¯ã‚Šé…ã‚Œãƒ»æ‰‹å…ˆè£œæ­£ã‚’å¢—ã‚„ã—ã«ãã„å¸¯åŸŸã‚’å„ªå…ˆã—ã¾ã™ã€‚ |")
        lines.append(f"| ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ | {ft['ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹']} | åˆ‡ã‚Šè¿”ã—ã‹ã‚‰ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã¾ã§ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ•´ãˆã€å†ç¾æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚ |")
        lines.append(f"| ã‚­ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ | {ft['ã‚­ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ']} | ç¾çŠ¶ã®å›è»¢é‡ã¨æ‰‹é¦–ã®ä½¿ã„æ–¹ã®å‚¾å‘ã‚’è¸ã¾ãˆã€æ‰“ã¡å‡ºã—ã¨æ“ä½œæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã™ã€‚ |")
        lines.append(f"| ãƒˆãƒ«ã‚¯ | {ft['ãƒˆãƒ«ã‚¯']} | ãƒ˜ãƒƒãƒ‰ã‚¹ãƒ”ãƒ¼ãƒ‰å¸¯ã‚’è€ƒæ…®ã—ã€æˆ»ã‚Šéããƒ»é…ã‚Œéãã‚’é¿ã‘ã‚‹ç¯„å›²ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ |")
        lines.append("\nâ€»æœ¬è¨ºæ–­ã¯éª¨æ ¼åˆ†æã«åŸºã¥ãå‚¾å‘ææ¡ˆã§ã™ã€‚")
        lines.append("ãƒªã‚·ãƒ£ãƒ•ãƒˆã«ã¤ã„ã¦ã¯ã€ãŠå®¢æ§˜ã”è‡ªèº«ã§å®Ÿéš›ã«è©¦æ‰“ã—ãŸä¸Šã§ã”æ¤œè¨ãã ã•ã„ã€‚\n")

    # 10 (premium only) â€“ requested volume and closing sentence
    if is_premium:
        lines.append("\n## 10. ã¾ã¨ã‚ï¼ˆæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼‰\n")
        lines.append(sections.get("sec10_text", "").strip())

    return "\n".join(lines).strip()


# ==================================================
# Routes
# ==================================================
@app.route("/health", methods=["GET"])
def health():
    return jsonify(
        {
            "ok": True,
            "service": "gate-swing-server",
            "queue_location": TASK_QUEUE_LOCATION,
            "queue_name": TASK_QUEUE_NAME,
            "force_premium": FORCE_PREMIUM,
            "has_firestore": bool(db),
            "has_line": bool(line_bot_api and handler),
            "has_tasks": bool(tasks_client and queue_path),
        }
    )


@app.route("/webhook", methods=["POST"])
def webhook():
    if not handler:
        abort(500)
    signature = request.headers.get("X-Line-Signature", "")
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    except Exception:
        safe_print_exc("[Webhook] handler error")
        abort(500)

    return "OK"


@handler.add(MessageEvent, message=TextMessage)  # type: ignore[misc]
def handle_text_message(event: MessageEvent):
    """
    Optional: accept user inputs for 09 fitting:
      HS:45 ãƒŸã‚¹:ã‚¹ãƒ©ã‚¤ã‚¹ æ€§åˆ¥:ç”· ç•ªæ‰‹:DR
    Store for next video.
    """
    user_id = event.source.user_id
    text = getattr(event.message, "text", "") or ""
    prof = parse_profile_text(text)

    if prof:
        set_pending_profile(user_id, prof)
        safe_line_reply(
            event.reply_token,
            "âœ… å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n"
            "æ¬¡ã«é€ã‚‹å‹•ç”»ã®è¨ºæ–­ã§ã€ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è¨ºæ–­ï¼ˆæœ‰æ–™ç‰ˆï¼‰ã«å‚è€ƒæƒ…å ±ã¨ã—ã¦åæ˜ ã—ã¾ã™ã€‚\n"
            "ï¼ˆä¾‹ï¼šHS:45 ãƒŸã‚¹:ã‚¹ãƒ©ã‚¤ã‚¹ æ€§åˆ¥:ç”· ç•ªæ‰‹:DRï¼‰"
        )
    else:
        safe_line_reply(
            event.reply_token,
            "ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã—ãŸã€‚\n"
            "ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è¨ºæ–­ç”¨ã«å…¥åŠ›ã™ã‚‹å ´åˆã¯ã€ä¾‹ã®å½¢å¼ã§é€ã£ã¦ãã ã•ã„ã€‚\n"
            "ä¾‹ï¼šHS:45 ãƒŸã‚¹:ã‚¹ãƒ©ã‚¤ã‚¹ æ€§åˆ¥:ç”· ç•ªæ‰‹:DR"
        )


@handler.add(MessageEvent, message=VideoMessage)  # type: ignore[misc]
def handle_video_message(event: MessageEvent):
    user_id = event.source.user_id
    message_id = event.message.id
    report_id = f"{user_id}_{message_id}"

    # Determine plan (dev stage: force premium)
    is_premium = True if FORCE_PREMIUM else False
    plan_label = "å…¨æ©Ÿèƒ½ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼" if is_premium else "ç„¡æ–™ç‰ˆ"

    # Pull pending profile (optional)
    pending_profile = pop_pending_profile(user_id)

    # 1) Firestore initial
    firestore_safe_set(
        report_id,
        {
            "user_id": user_id,
            "message_id": message_id,
            "status": "PROCESSING",
            "created_at": fbfirestore.SERVER_TIMESTAMP if db else None,
            "is_premium": is_premium,
            "plan_type": "preview" if is_premium else "free",
            "summary": "å‹•ç”»è§£æã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚",
            "profile": pending_profile,
        },
    )

    # 2) enqueue
    try:
        task_name = create_cloud_task(report_id=report_id, user_id=user_id, message_id=message_id)
        firestore_safe_update(report_id, {"task_name": task_name})
    except NotFound:
        firestore_safe_update(
            report_id,
            {"status": "TASK_QUEUE_NOT_FOUND", "summary": f"Queue not found: {TASK_QUEUE_NAME} @ {TASK_QUEUE_LOCATION}"},
        )
        safe_line_reply(event.reply_token, "ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã€‘ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚")
        return
    except PermissionDenied:
        firestore_safe_update(
            report_id,
            {"status": "TASK_PERMISSION_DENIED", "summary": "Cloud Tasks permission denied"},
        )
        safe_line_reply(event.reply_token, "ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã€‘ã‚¿ã‚¹ã‚¯æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚")
        return
    except Exception as e:
        firestore_safe_update(
            report_id,
            {"status": "TASK_CREATE_FAILED", "summary": f"Task create failed: {str(e)[:200]}"},
        )
        safe_line_reply(event.reply_token, "ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã€‘å‹•ç”»è§£æã‚¸ãƒ§ãƒ–ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return

    # 3) first reply (your preferred polite message)
    safe_line_reply(event.reply_token, make_initial_reply(report_id, plan_label=plan_label))


@app.route("/worker/process_video", methods=["POST"])
def process_video_worker():
    started = now_ts()
    payload = request.get_json(silent=True) or {}

    report_id = payload.get("report_id")
    user_id = payload.get("user_id")
    message_id = payload.get("message_id")

    if not report_id or not user_id or not message_id:
        return jsonify({"status": "error", "message": "missing report_id/user_id/message_id"}), 400

    firestore_safe_update(report_id, {"status": "IN_PROGRESS", "summary": "å‹•ç”»è§£æã‚’å®Ÿè¡Œä¸­ã§ã™..."})

    temp_dir = None
    try:
        # plan
        report_doc = firestore_get(("reports", report_id)) or {}
        is_premium = bool(report_doc.get("is_premium", True))
        profile = report_doc.get("profile") or {}
        if not isinstance(profile, dict):
            profile = {}

        # temp files
        temp_dir = tempfile.mkdtemp()
        original_path = os.path.join(temp_dir, "original")
        input_path = os.path.join(temp_dir, "input.mp4")
        normalized_path = os.path.join(temp_dir, "normalized.mp4")

        # 1) download from LINE
        download_line_video_to_file(message_id, original_path)

        # 2) normalize container to mp4
        # Sometimes LINE content has no extension; attempt transcode anyway
        try:
            transcode_video(original_path, input_path)
        except Exception:
            # If fail, try assuming it's already mp4
            shutil.copyfile(original_path, input_path)

        # 3) re-transcode to stable mp4 for analysis
        transcode_video(input_path, normalized_path)

        # 4) mediapipe analyze
        raw_data = analyze_swing(normalized_path)
        if raw_data.get("error"):
            raise RuntimeError(raw_data["error"])

        # 5) Build sections by Gemini (premium only needs 02-06 & 10; free uses 07 too)
        sections = run_gemini_sections(raw_data, is_premium=is_premium)

        # 6) Assemble final markdown with fixed structure
        report_md = build_markdown_report(raw_data, sections, is_premium=is_premium, profile=profile)

        # Save
        firestore_safe_update(
            report_id,
            {
                "status": "COMPLETED",
                "summary": "AIã«ã‚ˆã‚‹è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚",
                "raw_data": raw_data,
                "ai_report": report_md,
                "elapsed_sec": round(now_ts() - started, 2),
                "completed_at": fbfirestore.SERVER_TIMESTAMP if db else None,
            },
        )

        # push done
        safe_line_push(user_id, make_done_push(report_id, is_premium=is_premium))
        return jsonify({"status": "success", "report_id": report_id}), 200

    except Exception as e:
        err = f"{type(e).__name__}: {str(e)}"
        safe_print_exc("[Worker] failed")
        firestore_safe_update(
            report_id,
            {
                "status": "ANALYSIS_FAILED",
                "summary": f"å‹•ç”»è§£æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚{err[:200]}",
                "elapsed_sec": round(now_ts() - started, 2),
            },
        )
        safe_line_push(user_id, "ã€è§£æã‚¨ãƒ©ãƒ¼ã€‘å‹•ç”»è§£æãŒå¤±æ•—ã—ã¾ã—ãŸã€‚åˆ¥è§’åº¦ã‚„æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
        # Return 200 to prevent infinite retries
        return jsonify({"status": "error", "message": "analysis failed"}), 200

    finally:
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)


@app.route("/api/report_data/<report_id>", methods=["GET"])
def api_report_data(report_id: str):
    if not db:
        return jsonify({"error": "Firestore is not initialized"}), 500
    doc = db.collection("reports").document(report_id).get()
    if not doc.exists:
        return jsonify({"error": "not found"}), 404
    data = doc.to_dict() or {}
    return jsonify(
        {
            "status": data.get("status", "UNKNOWN"),
            "summary": data.get("summary", ""),
            "is_premium": data.get("is_premium", True),
            "plan_type": data.get("plan_type", ""),
            "mediapipe_data": data.get("raw_data", {}),
            "ai_report_text": data.get("ai_report", ""),
            "profile": data.get("profile", {}),
        }
    )


# ==================================================
# Report View (Professional HTML, no green-heavy)
# - Safe from f-string brace bugs: return raw triple-quoted string with placeholder replacement
# - Markdown renderer handles headings, bold, lists, tables, <br>
# ==================================================
@app.route("/report/<report_id>", methods=["GET"])
def report_view(report_id: str):
    html = r"""
<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>GATE AIã‚¹ã‚¤ãƒ³ã‚°ãƒ‰ã‚¯ã‚¿ãƒ¼ è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    @media print { .no-print { display: none !important; } body { background:#fff !important; } }
    :root{
      --ink:#0f172a;        /* slate-900 */
      --muted:#475569;      /* slate-600 */
      --line:#e2e8f0;       /* slate-200 */
      --panel:#ffffff;
      --bg:#f1f5f9;         /* slate-100 */
      --accent:#1f2937;     /* gray-800 */
      --soft:#f8fafc;       /* slate-50 */
    }
    body{ background:var(--bg); color:var(--ink); }
    .card{ background:var(--panel); border:1px solid var(--line); border-radius:16px; }
    .h2{ font-size:1.35rem; font-weight:800; letter-spacing:.02em; margin-top:2.2rem; padding-bottom:.6rem; border-bottom:2px solid var(--ink); }
    .h3{ font-size:1.05rem; font-weight:800; margin-top:1.2rem; }
    .muted{ color:var(--muted); }
    .pill{ border:1px solid var(--line); background:var(--soft); border-radius:999px; padding:.25rem .6rem; font-size:.78rem; }
    .metric{
      background:var(--panel);
      border:1px solid var(--line);
      border-radius:14px;
      padding:12px;
      text-align:center;
    }
    .metric .k{ font-size:.78rem; color:var(--muted); }
    .metric .v{ font-size:1.5rem; font-weight:900; color:var(--ink); margin-top:2px; }
    .metric .s{ font-size:.75rem; color:var(--muted); margin-top:4px; }
    table{ width:100%; border-collapse:collapse; margin-top:12px; }
    th,td{ border:1px solid #cbd5e1; padding:10px; vertical-align:top; font-size:.95rem; }
    th{ background:#e2e8f0; font-weight:800; text-align:left; }
    .probox{
      border:1px solid var(--line);
      background:var(--soft);
      border-radius:14px;
      padding:12px;
      margin-top:10px;
    }
    .probox .tag{ font-weight:900; color:var(--accent); margin-bottom:6px; }
    .bullets{ margin-top:10px; }
    .bullets li{
      list-style:none;
      margin:8px 0;
      padding:10px 12px;
      border:1px solid var(--line);
      background:var(--panel);
      border-radius:12px;
      line-height:1.5;
    }
    .para{ line-height:1.75; margin-top:10px; }
    .loading{ padding:40px 0; text-align:center; color:var(--muted); }
  </style>
</head>
<body class="font-sans">
  <div class="max-w-4xl mx-auto p-4 md:p-8">

    <div class="card shadow-sm p-5">
      <div class="text-center">
        <div class="text-2xl font-extrabold tracking-wide">GATE AIã‚¹ã‚¤ãƒ³ã‚°ãƒ‰ã‚¯ã‚¿ãƒ¼</div>
        <div class="mt-2 flex flex-wrap items-center justify-center gap-2 text-sm muted">
          <span class="pill">è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ</span>
          <span class="pill">ID: <span id="rid"></span></span>
          <span class="pill">Status: <span id="status"></span></span>
        </div>
      </div>
      <div class="no-print flex justify-end mt-4">
        <button onclick="window.print()" class="px-4 py-2 rounded-lg bg-slate-900 text-white font-semibold hover:bg-slate-800">
          PDFã¨ã—ã¦ä¿å­˜ / å°åˆ·
        </button>
      </div>
    </div>

    <div id="loading" class="loading">ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­â€¦</div>

    <div id="main" class="hidden">
      <div class="card shadow-sm p-5 mt-6">
        <div class="h2">01. éª¨æ ¼è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿ï¼ˆAIãŒæ¸¬ã£ãŸæ•°å€¤ï¼‰</div>
        <div id="metrics" class="grid grid-cols-2 md:grid-cols-3 gap-3 mt-4"></div>
        <div class="mt-5">
          <div class="h3">å„æ•°å€¤ã®è¦‹æ–¹ï¼ˆç°¡å˜ãªèª¬æ˜ï¼‰</div>
          <div id="metric_desc" class="para muted"></div>
        </div>
      </div>

      <div class="card shadow-sm p-5 mt-6">
        <div class="h2">AIã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ</div>
        <div id="report" class="mt-3"></div>
      </div>
    </div>

  </div>

<script>
  const reportId = "__REPORT_ID__";
  document.getElementById("rid").innerText = reportId;

  function esc(s){
    return String(s ?? "")
      .replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;");
  }

  function clean(md){
    let t = String(md || "");
    t = t.replace(/```[\\s\\S]*?```/g, ""); // remove fenced blocks
    t = t.replace(/```/g, "");
    return t.trim();
  }

  function renderMetric(title, value, unit, ideal){
    const v = (value === undefined || value === null || value === "") ? "N/A" : String(value);
    return `
      <div class="metric">
        <div class="k">${esc(title)}</div>
        <div class="v">${esc(v)}${esc(unit||"")}</div>
        <div class="s">ç†æƒ³ç›®å®‰: ${esc(ideal||"-")}</div>
      </div>
    `;
  }

  // Very small Markdown renderer:
  // - h2 (##)
  // - h3 (###)
  // - bold (**)
  // - bullet list (- )
  // - tables (|...|)
  // - <br> kept as-is
  function mdToHtml(md){
    let t = clean(md);

    // Convert tables first: detect consecutive lines starting with |
    t = t.replace(/(^\\|.*\\|\\s*$\\n(?:^\\|.*\\|\\s*$\\n?)+)/gm, (block)=>{
      const lines = block.trim().split(/\\n/).filter(Boolean);
      if(lines.length < 2) return block;

      // split cells
      const rows = lines.map(l => l.trim().replace(/^\\|/,"").replace(/\\|$/,"").split("|").map(c=>c.trim()));
      // remove separator row like |---|---|
      const filtered = [];
      for(let i=0;i<rows.length;i++){
        const r = rows[i];
        const isSep = r.every(c => /^:?-{3,}:?$/.test(c));
        if(!isSep) filtered.push(r);
      }
      if(filtered.length < 1) return block;

      const head = filtered[0];
      const body = filtered.slice(1);

      let html = "<table><thead><tr>";
      head.forEach(c=> html += "<th>"+esc(c)+"</th>");
      html += "</tr></thead><tbody>";
      body.forEach(r=>{
        html += "<tr>";
        r.forEach(c=> html += "<td>"+c.replace(/<br>/g,"<br>")+"</td>");
        html += "</tr>";
      });
      html += "</tbody></table>";
      return html;
    });

    // Headings
    t = t.replace(/^##\\s+(.*)$/gm, '<div class="h2">$1</div>');
    t = t.replace(/^###\\s+(.*)$/gm, '<div class="h3">$1</div>');

    // Bold
    t = t.replace(/\\*\\*(.*?)\\*\\*/g, '<strong>$1</strong>');

    // Lists
    t = t.replace(/(^-\\s+.*(?:\\n-\\s+.*)*)/gm, (block)=>{
      const items = block.split(/\\n/).map(l=>l.replace(/^-\\s+/,"").trim()).filter(Boolean);
      if(!items.length) return block;
      return '<ul class="bullets">' + items.map(it=>'<li>'+it+'</li>').join('') + '</ul>';
    });

    // Paragraph breaks
    t = t.replace(/\\n\\n+/g, "</div><div class='para'>");
    t = "<div class='para'>" + t.replace(/\\n/g,"<br>") + "</div>";

    // Pro evaluation emphasis: wrap lines starting with **ãƒ—ãƒ­è©•ä¾¡** already present in markdown, so leave it.
    return t;
  }

  fetch("/api/report_data/" + reportId)
    .then(r=>r.json())
    .then(d=>{
      document.getElementById("loading").classList.add("hidden");
      document.getElementById("main").classList.remove("hidden");
      document.getElementById("status").innerText = d.status || "UNKNOWN";

      const m = d.mediapipe_data || {};
      const metrics = document.getElementById("metrics");

      metrics.innerHTML =
        renderMetric("è§£æãƒ•ãƒ¬ãƒ¼ãƒ æ•°", m.frame_count, "", "60ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Š") +
        renderMetric("æœ€å¤§è‚©å›è»¢", m.max_shoulder_rotation, "Â°", "ç´„80Â°ã€œ100Â°") +
        renderMetric("æœ€å°è…°å›è»¢", m.min_hip_rotation, "Â°", "ç´„35Â°ã€œ45Â°") +
        renderMetric("æœ€å¤§ã‚³ãƒƒã‚¯è§’", m.max_wrist_cock, "Â°", "ç´„90Â°ã€œ120Â°") +
        renderMetric("æœ€å¤§é ­ãƒ–ãƒ¬ï¼ˆSwayï¼‰", m.max_head_drift_x, "", "0.05ä»¥ä¸‹") +
        renderMetric("æœ€å¤§è†ãƒ–ãƒ¬ï¼ˆSwayï¼‰", m.max_knee_sway_x, "", "0.05ä»¥ä¸‹");

      // metric descriptions (pulled from report 01 section, already contains explanations)
      // We'll show a compact fixed text here for readability; the detailed is in markdown too.
      const desc = `
        <div><strong>è§£æãƒ•ãƒ¬ãƒ¼ãƒ æ•°</strong>ï¼šåˆ†æã®ç²’åº¦ã€‚ååˆ†ãªãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒã‚ã‚‹ã»ã©å‚¾å‘ãŒå®‰å®šã—ã¾ã™ã€‚</div>
        <div><strong>æœ€å¤§è‚©å›è»¢</strong>ï¼šä¸ŠåŠèº«ã®æ»è»¢é‡ã€‚å¤§ãã„ã»ã©ä½“å¹¹ä¸»å°ã«ãªã‚Šã‚„ã™ã„ç›®å®‰ã§ã™ã€‚</div>
        <div><strong>æœ€å°è…°å›è»¢</strong>ï¼šè…°ã®å›æ—‹é‡ã€‚æ»è»¢å·®ã®ä½œã‚Šã‚„ã™ã•ã«é–¢ä¿‚ã—ã¾ã™ã€‚</div>
        <div><strong>æœ€å¤§ã‚³ãƒƒã‚¯è§’</strong>ï¼šæ‰‹é¦–ã®ã‚³ãƒƒã‚¯é‡ã€‚é©æ­£ç¯„å›²ãŒå†ç¾æ€§ã«ç¹‹ãŒã‚Šã¾ã™ã€‚</div>
        <div><strong>æœ€å¤§é ­ãƒ–ãƒ¬</strong>ï¼šé ­ã®å·¦å³ãƒ–ãƒ¬ã€‚å°ã•ã„ã»ã©è»¸ãŒå®‰å®šã—ã‚„ã™ã„ã§ã™ã€‚</div>
        <div><strong>æœ€å¤§è†ãƒ–ãƒ¬</strong>ï¼šä¸‹åŠèº«ã®å·¦å³ãƒ–ãƒ¬ã€‚å°ã•ã„ã»ã©åœŸå°ãŒå®‰å®šã—ã‚„ã™ã„ã§ã™ã€‚</div>
      `;
      document.getElementById("metric_desc").innerHTML = desc;

      const reportMd = d.ai_report_text || "";
      document.getElementById("report").innerHTML = mdToHtml(reportMd);
    })
    .catch(()=>{
      document.getElementById("loading").innerText = "èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚";
    });
</script>

</body>
</html>
"""
    return html.replace("__REPORT_ID__", report_id), 200


# ==================================================
# Main
# ==================================================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", "8080"))
    app.run(host="0.0.0.0", port=port)
